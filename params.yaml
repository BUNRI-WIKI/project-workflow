# kcbert params
# more information: https://huggingface.co/docs/transformers/v4.44.2/en/main_classes/trainer#transformers.TrainingArguments
kcbert:
  base_model_name: beomi/kcbert-base
  model_param_save_path: ./kcbert_hatespeech_classifier.pth
  learning_rate: 1e-5
  batch_size: 11
  epochs: 1
  dataset_dir: ./data/hatespeech/hatespeech.csv
  test_size: 0.15
  random_state: 42

# YOLO params
# more information: https://docs.ultralytics.com/ko/modes/train/#train-settings
yolo:
  model: yolov10m.pt
  epochs: 3
  patience: 100
  batch: 16
  imgsz: 640
  cache: False
  device: None
  workers: 8
  name: yolov10m_v1
  pretrained: True
  optimizer: auto
  verbose: False
  lr0: 0.01
  momentum: 0.937
  weight_decay: 0.0005
  box: 7.5
  cls: 0.5
  dropout: 0.0
  val: True
